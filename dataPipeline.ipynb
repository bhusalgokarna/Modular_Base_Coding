{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "\n",
    "# Interface for loading data\n",
    "class LoadDataProcess(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def read_data(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "# Interface for loading data\n",
    "class DataCleaningProcess(ABC):\n",
    "    @abstractmethod\n",
    "    def validate_data(self):\n",
    "        pass \n",
    "    \n",
    "    @abstractmethod\n",
    "    def transform_data(self):\n",
    "        pass    \n",
    "    \n",
    "    @abstractmethod\n",
    "    def print_information(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileHandler(LoadDataProcess):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.data = self.read_data()\n",
    "    \n",
    "    def read_data(self):\n",
    "        data_list = []\n",
    "        try:\n",
    "            if os.path.isdir(self.path):\n",
    "                for file in os.listdir(self.path):\n",
    "                    file_path = os.path.join(self.path, file)\n",
    "                    if file.endswith(\".txt\"):\n",
    "                        data_list.append(pd.read_csv(file_path, sep='|', dtype=str))\n",
    "                    elif file.endswith(\".csv\"):\n",
    "                        data_list.append(pd.read_csv(file_path, dtype=str))\n",
    "                    elif file.endswith(\".xlsx\"):\n",
    "                        data_list.append(pd.read_excel(file_path, dtype=str))\n",
    "                    elif file.endswith(\".json\"):\n",
    "                        data_list.append(pd.read_json(file_path))\n",
    "            data = pd.concat(data_list, ignore_index=True)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading data: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(DataCleaningProcess):\n",
    "    def __init__(self, data):\n",
    "        \n",
    "        #self.data = data.copy()\n",
    "        self.data = data\n",
    "        self.keep_cols=[]\n",
    "        self.numeric_cols = ['DT_HOUR', 'MS_ACCT', 'MS_ACCT_WITH_DEAD', 'MS_ACCT_WITH_DEAD_30_DAYS', \n",
    "                              'MS_ACCT_WITH_MORY_INJ', 'MS_ACCT_WITH_SERLY_INJ', 'MS_ACCT_WITH_SLY_INJ']\n",
    "        self.date_col = 'DT_DAY'\n",
    "        \n",
    "    #Implement the validate_data method\n",
    "    def validate_data(self):\n",
    "        if self.data is None:\n",
    "            print(\"Data is empty\")\n",
    "        else:\n",
    "            # Remove the columns that are not useful to analysis of the data\n",
    "            for col in self.data.columns:\n",
    "                if col.endswith(\"_FR\") or col.startswith(\"CD\"):\n",
    "                    self.data.drop(col, axis=1, inplace=True)\n",
    "                else:\n",
    "                    self.keep_cols.append(col)\n",
    "            self.data = self.data[self.keep_cols]\n",
    "\n",
    "            # Remove leading/trailing spaces     \n",
    "            self.data[self.date_col] = self.data[self.date_col].str.strip()  \n",
    "            \n",
    "            # Change the correct dtypes of the columns to numeric\n",
    "            self.data[self.numeric_cols] = self.data[self.numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Feature Engineering for the date columns\n",
    "            self.data['Year'] = self.data[self.date_col].str[:4].astype('Int64', errors='ignore')\n",
    "            self.data['Month'] = self.data[self.date_col].str[5:7].astype('Int64', errors='ignore')\n",
    "            self.data['Day_of_Month'] = self.data[self.date_col].str[8:10].astype('Int64', errors='ignore') \n",
    "            self.data['total_Deaths'] = self.data['MS_ACCT_WITH_DEAD'] + self.data['MS_ACCT_WITH_DEAD_30_DAYS']\n",
    "\n",
    "            # Drop the date column\n",
    "            self.data.drop(self.date_col, axis=1, inplace=True)\n",
    "\n",
    "            \n",
    "\n",
    "            # Fill the missing values of province with Brussels\n",
    "            self.data['TX_PROV_DESCR_NL'] = self.data['TX_PROV_DESCR_NL'].replace(['', ' '], 'Brussels')\n",
    "            self.data.fillna({'TX_PROV_DESCR_NL': 'Brussels'}, inplace=True)\n",
    "            \n",
    "               \n",
    "            # Rename the columns\n",
    "            columns_rename = {\n",
    "                'DT_DAY': 'Day', 'DT_HOUR': 'Hour', 'TX_DAY_OF_WEEK_DESCR_NL': 'DayOfWeek',\n",
    "                'TX_BUILD_UP_AREA_DESCR_NL': 'BuiltUpArea', 'TX_COLL_TYPE_DESCR_NL': 'CollisionType',\n",
    "                'TX_LIGHT_COND_DESCR_NL': 'LightCondition', 'TX_ROAD_TYPE_DESCR_NL': 'RoadType',\n",
    "                'TX_MUNTY_DESCR_NL': 'Municipality', 'TX_ADM_DSTR_DESCR_NL': 'District',\n",
    "                'TX_PROV_DESCR_NL': 'Province', 'TX_RGN_DESCR_NL': 'Region', 'MS_ACCT': 'Accident',\n",
    "                'MS_ACCT_WITH_DEAD': 'AccidentsWithFatalities', 'MS_ACCT_WITH_DEAD_30_DAYS': 'AccidentsWithFatalities30Days',\n",
    "                'MS_ACCT_WITH_MORY_INJ': 'AccidentsWithMinorInjuries', 'MS_ACCT_WITH_SERLY_INJ': 'AccidentsWithSeriousInjuries',\n",
    "                'MS_ACCT_WITH_SLY_INJ': 'AccidentsWithSlightInjuries'\n",
    "            }\n",
    "            # This loop will rename the columns\n",
    "            for key, value in columns_rename.items():\n",
    "                self.data.rename(columns={key: value}, inplace=True)\n",
    "                \n",
    "            print(\"Data cleaned successfully\") \n",
    "            return self.data\n",
    "        \n",
    "    #Implement the transform_data method   \n",
    "    def transform_data(self, data, output_path):\n",
    "        self.output_Path = output_path\n",
    "        if os.path.exists(self.output_Path):\n",
    "            os.remove(self.output_Path)\n",
    "        data.to_csv(self.output_Path, index=False)\n",
    "        print(f\"Data saved successfully at {self.output_Path}\")\n",
    "\n",
    "    #Implement the print_information method\n",
    "    def print_information(self, data_to_print):\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Shape of the data: {data_to_print.shape}\\n\")\n",
    "        print(\"Data Info:\\n\")\n",
    "        data_to_print.info()\n",
    "        print(\"\\nStatistics of Data:\\n\")\n",
    "        print(data_to_print.describe().T)\n",
    "        print(\"\\nColumns of Dataframe:\\n\")\n",
    "        print(data_to_print.columns)\n",
    "        print(\"\\nDatatypes of Dataframe:\\n\")\n",
    "        print(data_to_print.dtypes)\n",
    "        print(\"\\nAre there any null values:\\n\")\n",
    "        print(data_to_print.isnull().sum())\n",
    "        print(f\"Top 5 rows of the dataframe:\\n\")\n",
    "        print(data_to_print.head())\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccidentDataPipeline:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "    def process_data(self):\n",
    "        reader = FileHandler(self.path)\n",
    "        original_df = reader.read_data()\n",
    "        processor = DataProcessor(original_df)\n",
    "        if not os.path.exists(\"Merge_Data\"):\n",
    "            os.makedirs(\"Merge_Data\")\n",
    "        processor.transform_data(original_df,'Merge_Data/Orignal_data.csv')\n",
    "        clean_df = processor.validate_data()\n",
    "        processor.transform_data(clean_df,'Merge_Data/Clean_data.csv')\n",
    "        return processor.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully at Merge_Data/Orignal_data.csv\n",
      "Data cleaned successfully\n",
      "Data saved successfully at Merge_Data/Clean_data.csv\n",
      "   Hour DayOfWeek          BuiltUpArea                          CollisionType  \\\n",
      "0    18   vrijdag  Buiten bebouwde kom  Tegen een hindernis buiten de rijbaan   \n",
      "1    18  woensdag  Buiten bebouwde kom                       Niet beschikbaar   \n",
      "2    13   maandag     Niet beschikbaar                     Met een voetganger   \n",
      "3    14    zondag  Binnen bebouwde kom                            Langs opzij   \n",
      "4     9  woensdag  Binnen bebouwde kom  Frontale botsing (of bij het kruisen)   \n",
      "\n",
      "                          LightCondition  \\\n",
      "0  Nacht, ontstoken openbare verlichting   \n",
      "1  Nacht, ontstoken openbare verlichting   \n",
      "2                    Bij klaarlichte dag   \n",
      "3                    Bij klaarlichte dag   \n",
      "4                    Bij klaarlichte dag   \n",
      "\n",
      "                                 RoadType Municipality  \\\n",
      "0  Gewestweg, provincieweg of gemeenteweg   Aartselaar   \n",
      "1  Gewestweg, provincieweg of gemeenteweg   Aartselaar   \n",
      "2  Gewestweg, provincieweg of gemeenteweg   Aartselaar   \n",
      "3  Gewestweg, provincieweg of gemeenteweg   Aartselaar   \n",
      "4  Gewestweg, provincieweg of gemeenteweg   Aartselaar   \n",
      "\n",
      "                   District             Province         Region  Accident  \\\n",
      "0  Arrondissement Antwerpen  Provincie Antwerpen  Vlaams Gewest         1   \n",
      "1  Arrondissement Antwerpen  Provincie Antwerpen  Vlaams Gewest         1   \n",
      "2  Arrondissement Antwerpen  Provincie Antwerpen  Vlaams Gewest         1   \n",
      "3  Arrondissement Antwerpen  Provincie Antwerpen  Vlaams Gewest         1   \n",
      "4  Arrondissement Antwerpen  Provincie Antwerpen  Vlaams Gewest         1   \n",
      "\n",
      "   AccidentsWithFatalities  AccidentsWithFatalities30Days  \\\n",
      "0                        0                              0   \n",
      "1                        0                              0   \n",
      "2                        0                              0   \n",
      "3                        0                              0   \n",
      "4                        0                              0   \n",
      "\n",
      "   AccidentsWithMinorInjuries  AccidentsWithSeriousInjuries  \\\n",
      "0                           0                             0   \n",
      "1                           0                             0   \n",
      "2                           0                             0   \n",
      "3                           0                             0   \n",
      "4                           0                             0   \n",
      "\n",
      "   AccidentsWithSlightInjuries  Year  Month  Day_of_Month  total_Deaths  \n",
      "0                            1  2019     11            29             0  \n",
      "1                            1  2019     12            11             0  \n",
      "2                            1  2019     12            30             0  \n",
      "3                            1  2019     12            15             0  \n",
      "4                            1  2019     11            27             0  \n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "def main():\n",
    "    path='Data'\n",
    "    try:\n",
    "        # Initialize the pipeline and process the data\n",
    "        pipeline = AccidentDataPipeline(path)\n",
    "        df = pipeline.process_data()\n",
    "        \n",
    "        # Print the first 5 rows of the dataframe\n",
    "        print(df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
